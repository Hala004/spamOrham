{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb0b1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11496/2782800752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly_express\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "import wordcloud\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"../dataset/spam.csv\", encoding='latin-1')\n",
    "df.head()\n",
    "\n",
    "\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
    "df.rename(columns = {'v1':'class_label','v2':'message'},inplace=True)\n",
    "df.head()\n",
    "\n",
    "fig = px.histogram(df, x=\"class_label\", color=\"class_label\", color_discrete_sequence=[\"#871fff\",\"#ffa78c\"])\n",
    "fig.show()\n",
    "\n",
    "fig = px.pie(df.class_label.value_counts(),labels='index', values='class_label', color=\"class_label\", color_discrete_sequence=[\"#871fff\",\"#ffa78c\"] )\n",
    "fig.show()\n",
    "\n",
    "df['length'] = df['message'].apply(len)\n",
    "df.head()\n",
    "\n",
    "\n",
    "fig = px.histogram(df, x=\"length\", color=\"class_label\", color_discrete_sequence=[\"#871fff\",\"#ffa78c\"] )\n",
    "fig.show()\n",
    "\n",
    "\n",
    "data_ham  = df[df['class_label'] == \"ham\"].copy()\n",
    "data_spam = df[df['class_label'] == \"spam\"].copy()\n",
    "\n",
    "def show_wordcloud(df, title):\n",
    "    text = ' '.join(df['message'].astype(str).tolist())\n",
    "    stopwords = set(wordcloud.STOPWORDS)\n",
    "    fig_wordcloud = wordcloud.WordCloud(stopwords=stopwords, background_color=\"#ffa78c\",\n",
    "                                        width = 3000, height = 2000).generate(text)\n",
    "    plt.figure(figsize=(15,15), frameon=True)\n",
    "    plt.imshow(fig_wordcloud)  \n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_wordcloud(data_spam, \"Spam messages\")\n",
    "\n",
    "\n",
    "show_wordcloud(data_ham, \"ham messages\")\n",
    "\n",
    "df['class_label'] = df['class_label'].map( {'spam': 1, 'ham': 0})\n",
    "\n",
    "# Replace email address with 'emailaddress'\n",
    "df['message'] = df['message'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')\n",
    "\n",
    "# Replace urls with 'webaddress'\n",
    "df['message'] = df['message'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "\n",
    "# Replace money symbol with 'money-symbol'\n",
    "df['message'] = df['message'].str.replace(r'Â£|\\$', 'money-symbol')\n",
    "\n",
    "# Replace 10 digit phone number with 'phone-number'\n",
    "df['message'] = df['message'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3\n",
    "  \n",
    "\n",
    "?[\\d]{4}$', 'phone-number')\n",
    "\n",
    "# Replace normal number with 'number'\n",
    "df['message'] = df['message'].str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n",
    "# remove punctuation\n",
    "df['message'] = df['message'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# remove whitespace between terms with single space\n",
    "df['message'] = df['message'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "# remove leading and trailing whitespace\n",
    "df['message'] = df['message'].str.replace(r'^\\s+|\\s*?$', ' ')\n",
    "\n",
    "# change words to lower case\n",
    "df['message'] = df['message'].str.lower()\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "\n",
    "\n",
    "ss = nltk.SnowballStemmer(\"english\")\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(ss.stem(term) for term in x.split()))\n",
    "\n",
    "\n",
    "sms_df = df['message']\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# creating a bag-of-words model\n",
    "all_words = []\n",
    "for sms in sms_df:\n",
    "    words = word_tokenize(sms)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)     \n",
    "\n",
    "\n",
    "print('Number of words: {}'.format(len(all_words)))4\n",
    "\n",
    "\n",
    "all_words.plot(10, title='Top 10 Most Common Words in Corpus');\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_vec=tfidf_model.fit_transform(sms_df)\n",
    "import pickle\n",
    "#serializing our model to a file called model.pkl\n",
    "pickle.dump(tfidf_model, open(\"../model/tfidf_model.pkl\",\"wb\"))\n",
    "tfidf_data=pd.DataFrame(tfidf_vec.toarray())\n",
    "tfidf_data.head()\n",
    "\n",
    "### Separating Columns\n",
    "df_train = tfidf_data.iloc[:4457]\n",
    "df_test = tfidf_data.iloc[4457:]\n",
    "\n",
    "target = df['class_label']\n",
    "df_train['class_label'] = target\n",
    "\n",
    "Y = df_train['class_label']\n",
    "X = df_train.drop('class_label',axis=1)\n",
    "\n",
    "# splitting training data into train and validation using sklearn\n",
    "from sklearn import model_selection\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_and_test(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(f'F1 score is: {f1_score(pred, y_test)}')\n",
    "\n",
    "for depth in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    lgbmodel = lgb.LGBMClassifier(max_depth=depth, n_estimators=200, num_leaves=40)\n",
    "    print(f\"Max Depth {depth}\")\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    train_and_test(lgbmodel, \"Light GBM\")\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "lgbmodel_bst = lgb.LGBMClassifier(max_depth=6, n_estimators=200, num_leaves=40)\n",
    "param_grid = {\n",
    "    'num_leaves': list(range(8, 92, 4)),\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [3, 4, 5, 6, 8, 12, 16, -1],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005],\n",
    "    'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10),\n",
    "    \"min_split_gain\": [0.0, 0.1, 0.01],\n",
    "    \"min_child_weight\": [0.001, 0.01, 0.1, 0.001],\n",
    "    \"min_child_samples\": [20, 30, 25],\n",
    "    \"subsample\": [1.0, 0.5, 0.8],\n",
    "}\n",
    "model = RandomizedSearchCV(lgbmodel_bst, param_grid, random_state=1)\n",
    "search = model.fit(X_train, y_train)\n",
    "search.best_params_\n",
    "\n",
    "\n",
    "best_model = lgb.LGBMClassifier(subsample=0.5,\n",
    "                            reg_lambda= 0.47777777777777775,\n",
    "                            reg_alpha= 0.5722222222222222,\n",
    "                            num_leaves= 88,\n",
    "                            min_split_gain= 0.01,\n",
    "                            min_data_in_leaf= 10,\n",
    "                            min_child_weight= 0.01,\n",
    "                            min_child_samples= 30,\n",
    "                            max_depth= 3,\n",
    "                            learning_rate= 0.1,\n",
    "                            bagging_freq= 3,\n",
    "                            bagging_fraction= 0.6,\n",
    "                            random_state=1)\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "prediction = best_model.predict(X_test)\n",
    "print(f'F1 score is: {f1_score(prediction, y_test)}')\n",
    "\n",
    "\n",
    "\n",
    "best_model.fit(tfidf_data, target)\n",
    "pickle.dump(best_model, open(\"../model/spam_model.pkl\",\"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490cc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
